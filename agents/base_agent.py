"""
Base Agent Class - Foundation for All Debate Agents
===================================================

Provides common functionality for all AI debate agents.
"""

import subprocess
import os
import time
import logging
from typing import Optional, Dict, Any
from abc import ABC, abstractmethod
import sys

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.error_handler import retry_with_backoff, RetryConfig, error_logger

logger = logging.getLogger(__name__)


class BaseDebateAgent(ABC):
    """Base class for all debate agents"""
    
    def __init__(self, agent_id: str, name: str, role: str, personality_type: str):
        self.agent_id = agent_id
        self.name = name
        self.role = role
        self.personality_type = personality_type
        self.conversation_history = []
        
        # Gemini CLI configuration
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        if not self.gemini_api_key:
            raise ValueError("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # Path to Gemini CLI (assuming it's in parent directory)
        self.gemini_cli_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 
            "gemini-cli.js"
        )
        
        logger.info(f"âœ… {self.name} ({self.personality_type}) åˆæœŸåŒ–å®Œäº†")
    
    @abstractmethod
    def get_system_prompt(self, topic: str, context: str = "") -> str:
        """Generate system prompt based on personality and context"""
        pass
    
    async def generate_response(self, topic: str, opponent_message: str = "", 
                              context: str = "", turn_number: int = 1) -> str:
        """Generate debate response using Gemini CLI"""
        
        # Build the full prompt
        system_prompt = self.get_system_prompt(topic, context)
        
        if opponent_message:
            full_prompt = f"""{system_prompt}

è­°è«–ã®ãƒˆãƒ”ãƒƒã‚¯: {topic}

ç›¸æ‰‹ã®ä¸»å¼µ: {opponent_message}

ã‚ãªãŸã®ã‚¿ãƒ¼ãƒ³ {turn_number} ã§ã™ã€‚ç›¸æ‰‹ã®ä¸»å¼µã«å¯¾ã—ã¦ã€ã‚ãªãŸã®ç«‹å ´ã‹ã‚‰å¿œç­”ã—ã¦ãã ã•ã„ã€‚
è«–ç†çš„ã§èª¬å¾—åŠ›ã®ã‚ã‚‹è­°è«–ã‚’å±•é–‹ã—ã¦ãã ã•ã„ã€‚"""
        else:
            full_prompt = f"""{system_prompt}

è­°è«–ã®ãƒˆãƒ”ãƒƒã‚¯: {topic}

ã“ã‚Œã¯è­°è«–ã®æœ€åˆã®ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚ã‚ãªãŸã®ç«‹å ´ã‹ã‚‰ã€ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦æœ€åˆã®ä¸»å¼µã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚
è«–ç†çš„ã§èª¬å¾—åŠ›ã®ã‚ã‚‹è­°è«–ã‚’å±•é–‹ã—ã¦ãã ã•ã„ã€‚"""
        
        logger.info(f"ðŸ¤– {self.name}: å¿œç­”ç”Ÿæˆä¸­...")
        
        try:
            # Execute Gemini CLI with retry logic
            env = os.environ.copy()
            env["GEMINI_API_KEY"] = self.gemini_api_key
            
            # Configure retry for API calls
            api_retry_config = RetryConfig(
                max_attempts=3,
                initial_delay=2.0,
                max_delay=30.0,
                exponential_base=2.0
            )
            
            @retry_with_backoff(
                config=api_retry_config,
                exceptions=(subprocess.TimeoutExpired, subprocess.CalledProcessError),
                on_retry=lambda e, attempt: logger.warning(
                    f"{self.name}: Retry attempt {attempt} after error: {str(e)}"
                )
            )
            def call_gemini_cli():
                start_time = time.time()
                result = subprocess.run(
                    ["node", self.gemini_cli_path, full_prompt],
                    capture_output=True,
                    text=True,
                    env=env,
                    timeout=60  # Increased timeout from 30s to 60s
                )
                end_time = time.time()
                
                if result.returncode != 0:
                    error_msg = result.stderr or "Unknown error"
                    raise subprocess.CalledProcessError(
                        result.returncode, 
                        ["node", self.gemini_cli_path], 
                        output=result.stdout,
                        stderr=error_msg
                    )
                
                return result, end_time - start_time
            
            # Call with retry logic
            result, response_time = call_gemini_cli()
            
            # Extract AI response (remove debug output)
            output_lines = result.stdout.strip().split('\n')
            ai_response = ""
            found_separator = False
            
            for line in output_lines:
                if "===" in line and "æ¤œç´¢ä¸­" in line:
                    found_separator = True
                    continue
                if found_separator:
                    ai_response += line + "\n"
            
            ai_response = ai_response.strip()
            if not ai_response:
                ai_response = result.stdout.strip()
            
            # Store in conversation history
            self.conversation_history.append({
                "turn": turn_number,
                "topic": topic,
                "opponent_message": opponent_message,
                "response": ai_response,
                "response_time": response_time,
                "timestamp": time.strftime('%Y-%m-%d %H:%M:%S')
            })
            
            logger.info(f"âœ… {self.name}: å¿œç­”ç”Ÿæˆå®Œäº† ({response_time:.2f}ç§’)")
            return ai_response
                
        except Exception as e:
            # Log error with full context
            error_context = {
                "agent_name": self.name,
                "turn_number": turn_number,
                "topic": topic,
                "error_type": type(e).__name__
            }
            
            user_message = error_logger.log_error(
                e, 
                context=error_context,
                user_message=f"{self.name}: å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
            )
            
            return user_message
    
    def get_agent_info(self) -> Dict[str, Any]:
        """Get agent information"""
        return {
            "agent_id": self.agent_id,
            "name": self.name,
            "role": self.role,
            "personality_type": self.personality_type,
            "conversation_history_length": len(self.conversation_history)
        }