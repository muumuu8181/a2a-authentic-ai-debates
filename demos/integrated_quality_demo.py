#!/usr/bin/env python3
"""
Integrated Quality Demo - Complete System Demonstration
======================================================

Demonstrates the full integration of:
- Retry logic (Oliver)
- Quality metrics (Luna)
- Checkpoint system (Luna)
- Session management
"""

import asyncio
import os
import sys
from datetime import datetime

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.session_manager import SessionManager
from core.quality_calculator import QualityCalculator
from core.checkpoint_manager import CheckpointManager, CheckpointType
from agents.specialized.debate_agent_a import DebateAgentA
from agents.specialized.debate_agent_b import DebateAgentB
import json


async def run_integrated_demo():
    """Run complete integrated demonstration"""
    
    print("\n" + "="*80)
    print("ğŸš€ Integrated Quality Demo - Full System Test")
    print("="*80)
    print("Features:")
    print("  âœ… Retry Logic (3x retry with exponential backoff)")
    print("  âœ… Quality Metrics (Real-time calculation)")
    print("  âœ… Checkpoint System (Auto-save after each turn)")
    print("  âœ… Authenticity Detection (Response Time Variance)")
    print("="*80 + "\n")
    
    # Initialize components
    session_manager = SessionManager()
    quality_calculator = QualityCalculator()
    checkpoint_manager = CheckpointManager()
    
    print("ğŸ“¦ Components initialized:")
    print(f"  - Session Manager: âœ…")
    print(f"  - Quality Calculator: âœ… (Luna's design)")
    print(f"  - Checkpoint Manager: âœ… (Luna's design)")
    print(f"  - Retry Handler: âœ… (Oliver's implementation)\n")
    
    # Create debate agents
    pro_agent = DebateAgentA.create_philosophical("æœªæ¥å“²å­¦è€…")
    con_agent = DebateAgentB.create_logical("ç¾å®Ÿä¸»ç¾©è€…")
    
    # Create session
    participants = [
        {"id": pro_agent.agent_id, "name": pro_agent.name, "role": "pro"},
        {"id": con_agent.agent_id, "name": con_agent.name, "role": "con"}
    ]
    
    topic = "æŠ€è¡“çš„ç‰¹ç•°ç‚¹ï¼ˆã‚·ãƒ³ã‚®ãƒ¥ãƒ©ãƒªãƒ†ã‚£ï¼‰ã¯äººé¡ã«ã¨ã£ã¦ç¦éŸ³ã‹ï¼Ÿ"
    
    session = session_manager.create_session(
        topic=topic,
        participants=participants,
        max_turns=6  # 3 turns each
    )
    
    print(f"ğŸ¯ Debate Session: {session.session_id}")
    print(f"ğŸ“ Topic: {topic}")
    print(f"ğŸ‘¥ Participants: {pro_agent.name} vs {con_agent.name}\n")
    
    # Quality tracking
    quality_history = []
    checkpoint_ids = []
    
    # Run debate with quality monitoring
    current_message = ""
    
    for turn in range(6):  # 6 turns total
        turn_number = turn + 1
        
        # Select agent
        if turn % 2 == 0:
            agent = pro_agent
            role = "ä¸»å¼µ"
        else:
            agent = con_agent
            role = "åè«–"
        
        print(f"--- Turn {turn_number}: {agent.name} ã®{role} ---")
        print(f"ğŸ¤” {agent.name} thinking...")
        
        try:
            # Generate response (with retry logic built-in)
            response = await agent.generate_response(
                topic=topic,
                opponent_message=current_message,
                turn_number=turn_number
            )
            
            print(f"âœ… Response generated successfully")
            
            # Add to session
            success = session_manager.add_turn(
                session_id=session.session_id,
                agent_id=agent.agent_id,
                agent_name=agent.name,
                message=response,
                response_time=agent.conversation_history[-1]['response_time']
            )
            
            if success:
                # Calculate quality metrics
                print(f"ğŸ“Š Calculating quality metrics...")
                
                # Get updated session
                updated_session = session_manager.get_session(session.session_id)
                
                # Check if session still exists (not completed)
                if updated_session:
                    session = updated_session
                    
                    # Calculate turn metrics
                    turn_metrics = quality_calculator.calculate_turn_metrics(
                        session.turn_history[-1],
                        session,
                        topic
                    )
                else:
                    # Session was completed, use last known state
                    turn_metrics = quality_calculator.calculate_turn_metrics(
                        session.turn_history[-1],
                        session,
                        topic
                    )
                
                # Display metrics
                print(f"   Coherence: {turn_metrics.coherence_score:.1%}")
                print(f"   Relevance: {turn_metrics.relevance_score:.1%}")
                print(f"   Diversity: {turn_metrics.diversity_score:.1%}")
                print(f"   Authenticity: {turn_metrics.authenticity_score:.1%}")
                print(f"   Response Time: {turn_metrics.response_time:.2f}s")
                
                # Create quality snapshot
                quality_snapshot = {
                    "coherence": turn_metrics.coherence_score,
                    "relevance": turn_metrics.relevance_score,
                    "diversity": turn_metrics.diversity_score,
                    "authenticity": turn_metrics.authenticity_score
                }
                
                quality_history.append(quality_snapshot)
                
                # Create checkpoint
                print(f"ğŸ’¾ Creating checkpoint...")
                checkpoint = checkpoint_manager.create_checkpoint(
                    session=session,
                    checkpoint_type=CheckpointType.AUTOMATIC,
                    quality_snapshot=quality_snapshot,
                    metadata={"turn": turn_number}
                )
                checkpoint_ids.append(checkpoint.checkpoint_id)
                print(f"   Checkpoint saved: {checkpoint.checkpoint_id[:8]}...")
                
                # Check for quality alerts
                if turn_metrics.authenticity_score < 0.4:
                    print(f"âš ï¸ ALERT: Low authenticity detected!")
                if turn_metrics.coherence_score < 0.6:
                    print(f"âš ï¸ ALERT: Low coherence detected!")
                
                # Show preview of response
                print(f"\nğŸ’¬ {agent.name}:")
                print("-" * 60)
                preview = response[:200] + "..." if len(response) > 200 else response
                print(preview)
                print("-" * 60 + "\n")
                
                # Update current message
                current_message = response
                
            else:
                print(f"âŒ Failed to add turn to session")
                
        except Exception as e:
            print(f"âŒ Error during turn {turn_number}: {str(e)}")
            
            # Emergency checkpoint
            print(f"ğŸš¨ Creating emergency checkpoint...")
            if session and hasattr(session, 'session_id'):
                emergency_checkpoint = checkpoint_manager.save_emergency_checkpoint(
                    session_id=session.session_id,
                    error=e,
                    session=session
                )
            if emergency_checkpoint:
                print(f"   Emergency checkpoint created")
        
        # Brief pause
        if turn < 5:
            await asyncio.sleep(2)
    
    # Final quality report
    print("\n" + "="*80)
    print("ğŸ“Š Final Quality Report")
    print("="*80)
    
    final_report = quality_calculator.calculate_session_quality(session)
    
    print(f"Overall Score: {final_report.overall_score:.1%}")
    print(f"  - Coherence: {final_report.coherence:.1%}")
    print(f"  - Relevance: {final_report.relevance:.1%}")
    print(f"  - Engagement: {final_report.engagement:.1%}")
    print(f"  - Authenticity: {final_report.authenticity:.1%}")
    
    if final_report.alerts:
        print(f"\nâš ï¸ Alerts:")
        for alert in final_report.alerts:
            print(f"  - {alert}")
    
    if final_report.recommendations:
        print(f"\nğŸ’¡ Recommendations:")
        for rec in final_report.recommendations:
            print(f"  - {rec}")
    
    # Response time analysis
    print(f"\nâ±ï¸ Response Time Analysis:")
    response_times = [t.response_time for t in session.turn_history]
    if response_times:
        import statistics
        print(f"  - Average: {statistics.mean(response_times):.2f}s")
        print(f"  - Variance: {statistics.variance(response_times):.2f}")
        print(f"  - Min: {min(response_times):.2f}s")
        print(f"  - Max: {max(response_times):.2f}s")
    
    # Checkpoint summary
    print(f"\nğŸ’¾ Checkpoint Summary:")
    print(f"  - Total checkpoints: {len(checkpoint_ids)}")
    print(f"  - Session can be recovered from any checkpoint")
    
    print("\n" + "="*80)
    print("âœ¨ Demo Complete!")
    print("="*80)
    
    return {
        "session_id": session.session_id,
        "quality_report": final_report,
        "checkpoint_count": len(checkpoint_ids)
    }


async def demonstrate_recovery():
    """Demonstrate checkpoint recovery"""
    print("\n" + "="*80)
    print("ğŸ”„ Checkpoint Recovery Demo")
    print("="*80)
    
    checkpoint_manager = CheckpointManager()
    
    # List recent checkpoints
    print("ğŸ“‹ Available checkpoints:")
    
    # (In real implementation, would list actual checkpoints)
    print("  - Auto-save checkpoints available for recovery")
    print("  - Emergency checkpoints from error scenarios")
    
    print("\nâœ… Recovery system ready")
    print("="*80)


async def main():
    """Main demo runner"""
    print("ğŸŒŸ Integrated Quality Demo - Oliver + Luna Collaboration")
    print("Demonstrating complete system integration\n")
    
    # Check environment
    if not os.getenv("GEMINI_API_KEY"):
        print("âŒ Error: GEMINI_API_KEY not set")
        return
    
    try:
        # Run main demo
        result = await run_integrated_demo()
        
        # Show recovery capability
        await demonstrate_recovery()
        
        print(f"\nâœ… All systems operational!")
        print(f"ğŸ“Š Quality tracking: Active")
        print(f"ğŸ’¾ Checkpoints: Enabled") 
        print(f"ğŸ”„ Retry logic: Protected")
        print(f"\nğŸ‰ Ready for Monday's demo with Boss!")
        
    except Exception as e:
        print(f"\nâŒ Demo error: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())